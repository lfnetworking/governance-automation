# =============================================================================
#  LFN Project Governance Automation Workflow
#  --------------------------------------------------------------------------------
#  PURPOSE
#  -------
#  This workflow aims to provide consistency and engagement to the governance and health-check processes for Projects across all Linux Foundation Networking (LFN) projects. It regularly assesses repositories under LFN's umbrella to ensure continuous alignment with community health, security standards, and lifecycle progression defined by the Technical Advisory Council (TAC). This information will be helpful to the Members of the Board when making strategic decisions.
#  The timing of the assessment would depend on their lifecycle phase and the metrics being checked. The timing will need to be customizable by the TAC.

#  CORE OBJECTIVES
#  ---------------
#  • **Automated Repository Assessment:**
#    - Periodically scan every repository within the LFN umbrella projects (and induction-candidate repositories).
#    - Read existing health metrics, including commit activity, contributor engagement, release history, and lifecycle status.
#    - Initially designed to operate without requiring elevated permissions or special GitHub GraphQL scopes, ensuring secure, transparent, and community-friendly operation.

#  • **Lifecycle Classification:**
#    - Clearly categorize repositories into one of seven TAC-defined lifecycle phases:
#      1. Spark (Candidate/New)
#      2. Incubation
#      3. Active Development
#      4. Stable
#      5. Maintenance/Long-Term Support (LTS)
#      6. Archive
#      7. Inaccessible (permissions issue or repository not found)
#    - Provide a simple, community-readable summary for easy tracking and oversight by project maintainers, Program Managers (PMs), and the TAC.

#  • **Friendly and Encouraging Community Engagement:**
#    - Automatically create/update one GitHub issue per organization (project-level) with clear, friendly, and actionable next-step suggestions to improve their project's lifecycle status.
#    - Issues will not impose strict deadlines, emphasizing encouragement and constructive guidance, with recommended adjustable check-ins for progress updates.
#    - Repositories classified as "Archive" or "Inaccessible" are intentionally excluded from next-step issues as they have reached terminal phases.

#  FUTURE ENHANCEMENTS
#  -------------------
#  • **Security and Health:**
#    - Incorporate OSSF Scorecard checks
#    - Open tickets to the orgs (project-level) with helpful steps they can take to improve their current OSSF scorecard
#
#  • **Governance and Leadership:**
#    - Technical Steering Committee (TSC) membership is often submitted as part of Induction levels beyond Spark (and possibly even at Spark), but it is not always maintained in GitHub.  With community
#      agreement, it may be easier to maintain in GitHub for automation, if we can agree on a standard
#
#  • **Flexible TAC Lifecycle Adjustment:**
#    - Provide a clear, documented mechanism to modify lifecycle phase datapoints based on official TAC approvals (authentication of approvals currently outside workflow scope, maintained by LF staff or authorized community maintainers for now discuss with community).

#  READABILITY & MAINTAINABILITY
#  -----------------------------
#  This workflow is intentionally designed to be both verbose and structured for readability and ease of community collaboration. Community members are encouraged to contribute suggestions, enhancements, or adjustments to the logic to ensure continuous improvement and alignment with community goals.

name: "LFN Project Governance Automation"

on:
  # Allows manual triggering from the GitHub Actions UI ('Actions' tab -> select workflow -> 'Run workflow')
  workflow_dispatch:
    inputs:
      # Input to select the operational mode when manually triggered
      mode:
        description: "Choose the run mode: 'test' (runs on subset?), 'review' (standard run), 'induction' (runs on specific repo/org)"
        required: true
        default: "review" # Default to standard review mode
        type: choice
        options: [test, review, induction]
      # Input for the organization, used only in 'induction' mode
      project_org:
        description: "(induction) GitHub org where the new project lives"
        required: false # Only required if mode is 'induction'
      # Input for the repository slug, used only in 'induction' mode (if specifying single repo)
      project_repo:
        description: "(induction) Specific repository slug <org>/<repo> (optional, processes only this repo in the org)"
        required: false # Optional for induction mode

  # Schedule the workflow to run automatically
  schedule:
    # Runs at 09:00 UTC every Monday (adjust cron expression as needed)
    - cron: "0 9 * * 1"  # Example: 09:00 UTC Monday → 02:00 PT

# Define permissions required by the workflow at the top level
permissions:
  contents: read          # Needed to checkout code, read repo metadata, list repos
  issues: write           # Needed to create/update governance summary issues
  pull-requests: write    # Often needed by actions interacting with PRs (can potentially be reduced)
  id-token: write         # Needed if using OIDC for authentication (e.g., with external services, not currently used here but good practice if needed later)
  actions: write          # Added: Needed for gh artifact upload

# Environment variables available to all jobs in the workflow
env:
  # Sets the GitHub token for all jobs. Using a specific LFN Admin Token for potentially elevated permissions if required across orgs.
  # Ensure this secret (LFN_ADMIN_TOKEN) is configured in the repository/organization settings.
  GITHUB_TOKEN: ${{ secrets.LFN_ADMIN_TOKEN }}

jobs:
  # =============================================================================
  # JOB 1: Enumerate Organizations
  # PURPOSE: Determines which organizations (projects) need to be processed.
  #          Reads the list of LFN organizations from '.lfn/projects.yaml'.
  #          Alternatively, if run in 'induction' mode, uses the manually provided org.
  # OUTPUT:  A JSON matrix ('matrix') where each element contains an organization name.
  # =============================================================================
  enumerate-projects: # Renaming to enumerate-orgs might be clearer, but keeping for consistency for now
    runs-on: ubuntu-latest # Use the latest available Ubuntu runner
    outputs:
      # Define the output 'matrix' which will contain the JSON object for the strategy
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      # Step 1.1: Checkout the repository containing this workflow
      - name: Checkout Repository Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1 # Fetch only the latest commit for efficiency

      # Step 1.2: Install necessary command-line tools
      - name: Install yq and jq
        run: sudo apt-get update -y && sudo apt-get install -y yq jq

      # Step 1.3: Build the organization matrix
      # This script determines the list of organizations to process.
      - name: Build org matrix
        id: set-matrix # Give this step an ID so its output can be referenced
        shell: bash    # Use bash shell for the script
        env:
          # Pass workflow inputs to the script environment
          MODE: ${{ github.event.inputs.mode || 'review' }} # Default to 'review' if not manually triggered
          PROJECT_ORG: ${{ github.event.inputs.project_org }}
          # PROJECT_REPO is now handled within the classify job if provided for induction
        run: |
          set -euo pipefail # Keep strict mode here as it's simpler logic

          declare -a org_list

          # --- Determine Org List ---
          if [[ "$MODE" == "induction" ]]; then
            if [[ -z "$PROJECT_ORG" ]]; then echo "ERROR: Project org must be provided for induction mode." >&2; exit 1; fi
            org_list+=("$PROJECT_ORG")
            echo "Processing single org (Induction): $PROJECT_ORG" >&2
          else
            if [[ ! -f ".lfn/projects.yaml" ]]; then echo "ERROR: .lfn/projects.yaml not found!" >&2; exit 1; fi
            # Read orgs into the bash array using yq and mapfile
            mapfile -t org_list < <(yq -r '.orgs[] // ""' .lfn/projects.yaml | grep -v '^$' ) # Read orgs, filter empty lines
            echo "Read ${#org_list[@]} orgs from .lfn/projects.yaml" >&2
          fi

          # --- Create Matrix ---
          total_orgs=${#org_list[@]}
          echo "Total organizations to process: $total_orgs" >&2
          if [ $total_orgs -eq 0 ]; then
            echo "ERROR: No organizations found to process." >&2
            echo "matrix={\"include\":[]}" >> "$GITHUB_OUTPUT"
            exit 0 # Exit successfully but with empty matrix
          fi

          # Prepare the 'include' array for the matrix: [ {"org": "org1"}, {"org": "org2"}, ... ]
          matrix_include_json=$(printf '%s\n' "${org_list[@]}" | jq -R '{org: .}' | jq -sc .)

          # Final matrix object structure: { "include": [ { "org": "org1" }, ... ] }
          final_matrix_json="{\"include\":${matrix_include_json}}"

          echo "matrix=${final_matrix_json}" >> "$GITHUB_OUTPUT"
          echo "Generated matrix for $total_orgs organizations." >&2
          echo "Matrix structure: $(echo $final_matrix_json | jq -c . | cut -c 1-200)..." >&2


  # =============================================================================
  # JOB 2: Classify Repositories per Organization
  # PURPOSE: Runs the classification logic for all repositories within a specific organization.
  #          This job uses a matrix strategy based on the organizations identified previously.
  # INPUT:   The 'matrix' output from 'enumerate-projects', containing organization names.
  # PROCESS: - For each organization job instance:
  #          - Checks out the main governance-automation repo.
  #          - Sets up Node.js and installs dependencies for the local action.
  #          - Lists all repositories within the current organization.
  #          - Loops through each repository slug.
  #          - For each repo: Clones it, runs the classification Node.js script directly,
  #            uploads the result artifact using GitHub CLI. Handles errors per repo.
  # =============================================================================
  classify:
    needs: enumerate-projects # Depends on the 'enumerate-projects' job
    # Condition to prevent running if the matrix 'include' array is empty
    if: ${{ needs.enumerate-projects.outputs.matrix != '' && fromJson(needs.enumerate-projects.outputs.matrix).include[0] != null }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false # Allow other orgs to process if one fails
      matrix: ${{ fromJson(needs.enumerate-projects.outputs.matrix) }} # Matrix iterates over org objects: { "org": "..." }
    steps:

      # Step 2.1: Checkout the main branch of this (governance-automation) repository.
      - name: Checkout governance-automation code (Org ${{ matrix.org }})
        uses: actions/checkout@v4
        with:
          ref: main

      # Step 2.2: Setup Node.js environment (once per org job).
      - name: Setup Node.js (Org ${{ matrix.org }})
        uses: actions/setup-node@v4
        with:
          node-version: '16'

      # Step 2.3: Install dependencies for the local classification action (once per org job).
      - name: Install Action Dependencies (Org ${{ matrix.org }})
        run: npm install
        working-directory: ${{ github.workspace }}/classify-config

      # Step 2.4: Process all repositories within the current organization.
      # This script now includes explicit error checking and debug tracing (set -x).
      - name: Process Repositories for Org ${{ matrix.org }}
        shell: bash
        env:
          # Pass specific repo slug if provided in induction mode, otherwise process all
          INDUCTION_REPO_SLUG: ${{ github.event.inputs.project_repo }}
          MODE: ${{ github.event.inputs.mode || 'review' }}
        run: |
          # Enable command tracing for detailed debugging output
          set -x

          current_org="${{ matrix.org }}"
          config_path=".github/workflows/classify-config.yml" # Relative path within checked out code
          repo_processed_count=0
          repo_error_count=0

          # Check if gh is installed (needed for repo list and artifact upload)
          if ! command -v gh &> /dev/null; then echo "ERROR: gh cli not found." >&2; exit 1; fi
          # Authenticate gh CLI using the job's GITHUB_TOKEN
          echo "Authenticating gh CLI..." >&2
          echo "${{ env.GITHUB_TOKEN }}" | gh auth login --with-token
          if [[ $? -ne 0 ]]; then echo "ERROR: gh auth login failed." >&2; exit 1; fi
          echo "gh CLI authenticated." >&2

          # --- List Repositories for the Current Org ---
          declare -a org_repos
          echo "Listing repositories for organization: $current_org..." >&2

          # If in induction mode AND a specific repo was given, only process that one
          if [[ "$MODE" == "induction" ]] && [[ -n "$INDUCTION_REPO_SLUG" ]] && [[ "$INDUCTION_REPO_SLUG" == "$current_org/"* ]]; then
             echo "Induction mode with specific repo: $INDUCTION_REPO_SLUG" >&2
             org_repos+=("$INDUCTION_REPO_SLUG")
          else
             # Otherwise, list all public repos in the org
             repo_list_json=$(GH_TOKEN=${{ env.GITHUB_TOKEN }} gh repo list "$current_org" --limit 1000 --json name --public -q '.' 2>/dev/null)
             gh_exit_code=$?
             # Check if the 'gh repo list' command failed
             if [[ $gh_exit_code -ne 0 ]]; then
                 echo "::error::Failed to list repos for '$current_org'. gh exit code: $gh_exit_code. Skipping org."
                 exit 1 # Fail the job if repo listing fails
             fi
             # Check if the list is empty or null
             if [[ -z "$repo_list_json" ]] || [[ "$repo_list_json" == "[]" ]]; then
                 echo "::warning::No public repositories found for '$current_org' or org is inaccessible. Skipping org."
                 exit 0 # Exit successfully, nothing to process for this org
             fi
             # Populate the array with <org>/<repo> slugs
             mapfile -t org_repos < <(echo "$repo_list_json" | jq -r '.[].name' | sed "s|^|$current_org/|") # Add org prefix
          fi

          echo "Found ${#org_repos[@]} repositories to process for $current_org." >&2
          if [ ${#org_repos[@]} -eq 0 ]; then
             echo "No repositories to process for $current_org." >&2
             exit 0 # Exit successfully
          fi

          # --- Loop Through Repositories in this Org ---
          for repo_slug in "${org_repos[@]}"; do
            if [[ -z "$repo_slug" ]]; then continue; fi # Safety check

            echo # Add blank line for readability
            echo "--- Processing repository: $repo_slug ---" >&2
            target_repo_path="./repo_temp" # Temporary checkout path
            result_json_path="./repo_result.json" # Temporary result file path
            safe_name=$(echo "$repo_slug" | sed 's|/|--|g') # Sanitize name for artifact
            artifact_name="${safe_name}.json"
            repo_failed=false # Flag for this specific repo

            # Clean up from previous iteration
            rm -f "$result_json_path"
            rm -rf "$target_repo_path"

            # --- Checkout target repo ---
            echo "Cloning $repo_slug..." >&2
            # Capture output AND exit code separately
            # Added || true to prevent immediate exit if clone fails, rely on exit code check
            git_output=$(git clone --depth 1 "https://github-actions:${{ env.GITHUB_TOKEN }}@github.com/${repo_slug}.git" "$target_repo_path" 2>&1 || true)
            git_exit_code=$?

            phase_value="Unknown"
            checkout_successful=false
            # Check exit code explicitly
            if [[ $git_exit_code -eq 0 ]]; then
              echo "Clone successful." >&2
              checkout_successful=true
            else
              echo "::error::Failed to clone $repo_slug. Exit code: $git_exit_code."
              echo "Git Output: $git_output" # Log git output on error
              phase_value="Checkout Failed"
              repo_failed=true # Mark repo as failed
              # Create result JSON for checkout failure
              printf '{"phase": "%s", "error": "Checkout failed", "details": "%s"}\n' "$phase_value" "$(echo "$git_output" | jq -Rsa .)" > "$result_json_path"
            fi

            # --- Run Classification Script ---
            if [[ "$checkout_successful" == true ]]; then
              echo "Running classification script for $repo_slug..." >&2
              # Execute the Node.js script directly, capture exit code
              # Added || true to prevent immediate exit if node fails, rely on exit code check
              INPUT_REPO="$repo_slug" \
              INPUT_CONFIG_PATH="$config_path" \
              GITHUB_TOKEN="${{ env.GITHUB_TOKEN }}" \
              node "${{ github.workspace }}/classify-config/index.js" || true
              node_exit_code=$?

              # Check exit code explicitly
              if [[ $node_exit_code -ne 0 ]]; then
                 echo "::error::Classification script failed for $repo_slug with exit code $node_exit_code."
                 phase_value="Classification Error"
                 repo_failed=true
                 # Create error JSON
                 printf '{"phase": "%s", "error": "Classification script failed", "exit_code": %s}\n' "$phase_value" "$node_exit_code" > "$result_json_path"
              # Check if script produced output file as expected
              elif [[ -f "${{ github.workspace }}/repo.json" ]]; then
                 mv "${{ github.workspace }}/repo.json" "$result_json_path"
                 echo "Classification script ran, result moved to $result_json_path" >&2
                 # Read phase, handle read errors
                 phase_value=$(jq -r '.phase // "Unknown"' "$result_json_path" 2>/dev/null || echo "Read Error")
                 if [[ "$phase_value" == "Read Error" ]]; then
                    echo "::error::Failed to read phase from generated $result_json_path for $repo_slug"
                    repo_failed=true
                    # Overwrite result file with read error info
                    printf '{"phase": "%s", "error": "Failed to read phase from script output"}\n' "$phase_value" > "$result_json_path"
                 fi
              else
                 # This case means node script succeeded (exit 0) but didn't create the file
                 echo "::error::Classification script completed successfully but did not produce repo.json for $repo_slug"
                 phase_value="Classification Error"
                 repo_failed=true
                 printf '{"phase": "%s", "error": "Classification script did not produce output file"}\n' "$phase_value" > "$result_json_path"
              fi
            fi # end if checkout_successful

            echo "Final phase for $repo_slug: $phase_value" >&2

            # --- Upload Artifact ---
            # Ensure result file exists before uploading
            if [[ ! -f "$result_json_path" ]]; then
               echo "::error::Result file $result_json_path not found for $repo_slug. Cannot upload artifact."
               repo_failed=true
               # Optionally create a placeholder artifact if needed by publish-report
               # printf '{"phase": "Error", "error": "Result file missing before upload"}\n' > "$result_json_path"
               # gh artifact upload "$result_json_path" --name "$artifact_name" || true
            else
               echo "Uploading artifact $artifact_name..." >&2
               # Added || true to prevent immediate exit if upload fails, rely on exit code check
               gh artifact upload "$result_json_path" --name "$artifact_name" || true
               gh_artifact_exit_code=$?
               # Check exit code explicitly
               if [[ $gh_artifact_exit_code -ne 0 ]]; then
                 echo "::error::Failed to upload artifact $artifact_name for $repo_slug. gh exit code: $gh_artifact_exit_code"
                 repo_failed=true # Mark repo as failed if upload fails
               else
                 echo "Artifact $artifact_name uploaded successfully." >&2
               fi
            fi

            # Increment counters
            ((repo_processed_count++))
            if [[ "$repo_failed" == true ]]; then
               ((repo_error_count++))
            fi

            # Clean up for next repo
            rm -f "$result_json_path"
            rm -rf "$target_repo_path"
            echo "--- Finished processing repository: $repo_slug ---" >&2

            # Optional: Add a small delay to avoid hitting API rate limits too quickly
            # sleep 1

          done # End of loop through repos for the org

          echo "Finished processing Org ${current_org}. Processed: $repo_processed_count, Errors: $repo_error_count." >&2

          # Decide if the job should fail if any repo had an error
          if [[ $repo_error_count -gt 0 ]]; then
            echo "::error::Encountered $repo_error_count errors while processing repositories for $current_org."
            # exit 1 # Uncomment this line to make the whole org job fail if any repo fails
          fi


  # =============================================================================
  # JOB 3: Publish Report
  # PURPOSE: Aggregates the classification results from all repositories (across
  #          all orgs), generates a Markdown summary report, and posts/updates
  #          that report as a GitHub issue in the main governance-automation repository.
  # INPUT:   Artifacts uploaded by the 'classify' job instances (one per repo).
  # PROCESS: - Downloads all artifacts.
  #          - Parses each downloaded JSON file to get the repo and phase.
  #          - Builds the Markdown report ('summary.md') as before.
  #          - Uses github-script to find/create/update the summary issue.
  #          - Optionally notifies Slack.
  # =============================================================================
  publish-report:
    needs: classify # Depends on the completion of all 'classify' org jobs
    runs-on: ubuntu-latest
    if: always() # Run even if some classify jobs failed
    steps:
      # Step 3.1: Download all artifacts produced by the 'classify' jobs.
      - name: Download classification artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts # Download all available artifacts

      # Step 3.2: Build the Markdown Summary Report.
      - name: Build Markdown Report
        id: build-md
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v jq &> /dev/null; then
            echo "jq not found, installing..." >&2
            sudo apt-get update -y && sudo apt-get install -y jq
          fi

          declare -A rows_data
          echo "Scanning artifacts directory: $(pwd)/artifacts" >&2

          # Find all downloaded JSON files (*.json) inside the artifact directories (e.g., artifacts/org--repo.json/*.json)
          while IFS= read -r -d $'\0' file; do
            dir=$(dirname "$file") # Directory is artifacts/org--repo.json
            artifact_name_with_ext=$(basename "$dir") # org--repo.json
            artifact_name=${artifact_name_with_ext%.json} # org--repo

            full=${artifact_name//--/\/}
            project=${full%%/*}
            repo=${full#*/}

            if [[ -f "$file" ]]; then
              # Attempt to read phase, handle potential errors during read/parse
              phase=$(jq -r '.phase // "Unknown"' "$file" 2>/dev/null)
              jq_exit_code=$?
              # Check jq exit code and if phase is null/empty string
              if [[ $jq_exit_code -ne 0 ]] || [[ -z "$phase" ]] || [[ "$phase" == "null" ]]; then
                # If jq failed or phase is empty/null, try reading error field
                error_msg=$(jq -r '.error // ""' "$file" 2>/dev/null)
                if [[ -n "$error_msg" ]]; then
                   # Sanitize error message for Markdown table (optional)
                   # error_msg=$(echo "$error_msg" | sed 's/|/\\|/g')
                   phase="Error: $error_msg" # Use error message as phase
                else
                   phase="Unknown (Parse Error)" # Fallback if no error field
                fi
                echo "Warning: Could not parse phase or phase was null/empty in $file ($artifact_name). Setting phase to '$phase'." >&2
              fi
            else
              phase="Unknown (Missing JSON)"
              echo "Warning: JSON file not found in $dir ($artifact_name)" >&2
            fi

            row_line="| [$repo](https://github.com/$project/$repo) | $phase |"
            if [[ -z "${rows_data[$project]:-}" ]]; then
              rows_data[$project]="$row_line"
            else
              rows_data[$project]+=$'\n'"$row_line"
            fi
          # Find *.json files exactly two levels deep (artifacts/<artifact_name>/result.json)
          done < <(find artifacts -mindepth 2 -maxdepth 2 -name '*.json' -print0)


          if [ ${#rows_data[@]} -eq 0 ]; then
            echo "WARNING: No valid artifact data found to generate report." >&2
            echo "# LFN Project Lifecycle Summary" > summary.md
            echo "" >> summary.md
            echo "*No project data processed successfully. Check the 'classify' job logs for errors.*" >> summary.md
          else
            {
              echo "# LFN Project Lifecycle Summary"
              echo ""
              echo "Generated on: $(date -u)"
              echo "Workflow Run: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}>"
              echo ""
              sorted_projects=()
              while IFS= read -r key; do
                  sorted_projects+=("$key")
              done < <(printf '%s\n' "${!rows_data[@]}" | sort)

              for project in "${sorted_projects[@]}"; do
                echo
                echo "## $project"
                echo "| Repository | Phase |"
                echo "|------------|-------|"
                # Sort rows: Errors/Unknown first, then by phase, then by repo name
                mapfile -t sorted_lines < <(printf '%s\n' "${rows_data[$project]}" | awk -F'|' '{gsub(/^[ \t]+|[ \t]+$/, "", $3); if ($3 ~ /^Error|^Unknown|^Checkout Failed|^Classification Error/) print "0"$0; else print "1"$0 }' | sort -t'|' -k1,1 -k3,3 -k2,2 | sed 's/^.//')
                printf '%s\n' "${sorted_lines[@]}"
              done
            } > summary.md
          fi

          echo "Generated summary.md:" >&2
          cat summary.md >&2

          {
            echo 'summary<<EOF'
            cat summary.md
            echo 'EOF'
          } >> "$GITHUB_OUTPUT"

          cat summary.md >> "$GITHUB_STEP_SUMMARY"

      # Step 3.3: Create or Update the Governance Summary Issue
      - name: Create or update governance issue
        uses: actions/github-script@v7
        with:
          github-token: ${{ env.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            // Note: 'core', 'github', and 'context' are automatically provided by actions/github-script@v7
            let body = "Failed to read summary.md";
            if (fs.existsSync('summary.md')) {
              body = fs.readFileSync('summary.md', 'utf8');
            } else {
              core.warning("summary.md not found for issue creation/update.");
              body = "Error: Workflow failed to generate summary report.";
            }
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const title = 'Automated LFN Project Lifecycle Summary';
            const token = process.env.GITHUB_TOKEN;
            if (!token) {
              core.setFailed('GITHUB_TOKEN not found in environment.');
              return;
            }
            // Use the pre-authenticated 'github' object provided by the action
            try {
              const issues = await github.paginate(github.rest.issues.listForRepo, {
                owner, repo, labels: 'lfn-governance', state: 'open'
              });
              const existing = issues.find(i => i.title === title);
              if (existing) {
                core.info(`Found existing issue #${existing.number}. Updating...`);
                await github.rest.issues.update({ owner, repo, issue_number: existing.number, body });
                core.info(`Updated issue #${existing.number}`);
              } else {
                core.info("No existing governance issue found. Creating new issue...");
                await github.rest.issues.create({ owner, repo, title, body, labels: ['lfn-governance'] });
                core.info('Created new governance issue');
              }
            } catch (error) {
              core.setFailed(`Failed to create or update governance issue: ${error.message}`);
              console.error("Error details:", error);
            }

      # Step 3.4: Optional Slack Notification
      - name: Notify Slack (optional)
        if: ${{ env.SLACK_WEBHOOK_URL != '' }}
        uses: slackapi/slack-github-action@v1.24.0
        with:
          payload: |
            {
              "text": ":clipboard: LFN governance summary updated for *${{ github.repository }}* – <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|view run>"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
