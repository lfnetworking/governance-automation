# =============================================================================
#  LFN Project Governance Automation Workflow
#  --------------------------------------------------------------------------------
#  PURPOSE
#  -------
#  This workflow aims to provide consistency and engagement to the governance and health-check processes for Projects across all Linux Foundation Networking (LFN) projects. It regularly assesses repositories under LFN's umbrella to ensure continuous alignment with community health, security standards, and lifecycle progression defined by the Technical Advisory Council (TAC). This information will be helpful to the Members of the Board when making strategic decisions.
#  The timing of the assessment would depend on their lifecycle phase and the metrics being checked. The timing will need to be customizable by the TAC.

#  CORE OBJECTIVES
#  ---------------
#  • **Automated Repository Assessment:**
#    - Periodically scan every repository within the LFN umbrella projects (and induction-candidate repositories).
#    - Read existing health metrics, including commit activity, contributor engagement, release history, and lifecycle status.
#    - Initially designed to operate without requiring elevated permissions or special GitHub GraphQL scopes, ensuring secure, transparent, and community-friendly operation.

#  • **Lifecycle Classification:**
#    - Clearly categorize repositories into one of seven TAC-defined lifecycle phases:
#      1. Spark (Candidate/New)
#      2. Incubation
#      3. Active Development
#      4. Stable
#      5. Maintenance/Long-Term Support (LTS)
#      6. Archive
#      7. Inaccessible (permissions issue or repository not found)
#    - Provide a simple, community-readable summary for easy tracking and oversight by project maintainers, Program Managers (PMs), and the TAC.

#  • **Friendly and Encouraging Community Engagement:**
#    - Automatically create/update one GitHub issue per organization (project-level) with clear, friendly, and actionable next-step suggestions to improve their project's lifecycle status.
#    - Issues will not impose strict deadlines, emphasizing encouragement and constructive guidance, with recommended adjustable check-ins for progress updates.
#    - Repositories classified as "Archive" or "Inaccessible" are intentionally excluded from next-step issues as they have reached terminal phases.

#  FUTURE ENHANCEMENTS
#  -------------------
#  • **Security and Health:**
#    - Incorporate OSSF Scorecard checks
#    - Open tickets to the orgs (project-level) with helpful steps they can take to improve their current OSSF scorecard
#
#  • **Governance and Leadership:**
#    - Technical Steering Committee (TSC) membership is often submitted as part of Induction levels beyond Spark (and possibly even at Spark), but it is not always maintained in GitHub.  With community
#      agreement, it may be easier to maintain in GitHub for automation, if we can agree on a standard
#
#  • **Flexible TAC Lifecycle Adjustment:**
#    - Provide a clear, documented mechanism to modify lifecycle phase datapoints based on official TAC approvals (authentication of approvals currently outside workflow scope, maintained by LF staff or authorized community maintainers for now discuss with community).

#  READABILITY & MAINTAINABILITY
#  -----------------------------
#  This workflow is intentionally designed to be both verbose and structured for readability and ease of community collaboration. Community members are encouraged to contribute suggestions, enhancements, or adjustments to the logic to ensure continuous improvement and alignment with community goals.

name: "LFN Project Governance Automation"

on:
  # Allows manual triggering from the GitHub Actions UI ('Actions' tab -> select workflow -> 'Run workflow')
  workflow_dispatch:
    inputs:
      # Input to select the operational mode when manually triggered
      mode:
        description: "Choose the run mode: 'test' (runs on subset?), 'review' (standard run), 'induction' (runs on specific repo/org)"
        required: true
        default: "review" # Default to standard review mode
        type: choice
        options: [test, review, induction]
      # Input for the organization, used only in 'induction' mode
      project_org:
        description: "(induction) GitHub org where the new project lives"
        required: false # Only required if mode is 'induction'
      # Input for the repository slug, used only in 'induction' mode (if specifying single repo)
      project_repo:
        description: "(induction) Specific repository slug <org>/<repo> (optional, processes only this repo in the org)"
        required: false # Optional for induction mode

  # Schedule the workflow to run automatically
  schedule:
    # Runs at 09:00 UTC every Monday (adjust cron expression as needed)
    - cron: "0 9 * * 1"  # Example: 09:00 UTC Monday → 02:00 PT

# Define permissions required by the workflow at the top level
permissions:
  contents: read          # Needed to checkout code, read repo metadata, list repos
  issues: write           # Needed to create/update governance summary issues
  pull-requests: write    # Often needed by actions interacting with PRs (can potentially be reduced)
  id-token: write         # Needed if using OIDC for authentication (e.g., with external services, not currently used here but good practice if needed later)
  actions: write          # Needed for actions/upload-artifact

# Environment variables available to all jobs in the workflow
env:
  # Sets the GitHub token for all jobs. Using a specific LFN Admin Token for potentially elevated permissions if required across orgs.
  # Ensure this secret (LFN_ADMIN_TOKEN) is configured in the repository/organization settings and has appropriate scopes (e.g., 'repo').
  GITHUB_TOKEN: ${{ secrets.LFN_ADMIN_TOKEN }}
  PROJECT_CONFIG_PATH: '.lfn/projects.yaml'
  # --- PATH UPDATED ---
  CLASSIFY_CONFIG_PATH: '.lfn/classify-config.yml' # Path to the classification rules
  ISSUES_CONFIG_PATH: '.lfn/issues-config.yml' # Path to issue templates
  CLASSIFY_ACTION_PATH: './classify-config' # Path to the local JS action directory
  GOVERNANCE_ISSUE_TITLE: "Quarterly LFN Governance & Lifecycle Review" # Standard title for created issues


jobs:
  # =============================================================================
  # JOB 1: Enumerate Organizations
  # PURPOSE: Determines which organizations (projects) need to be processed.
  #          Reads the list of LFN organizations from '.lfn/projects.yaml'.
  #          Alternatively, if run in 'induction' mode, uses the manually provided org.
  # OUTPUT:  A JSON matrix ('matrix') where each element contains an organization name.
  # =============================================================================
  enumerate-projects: # Renaming to enumerate-orgs might be clearer, but keeping for consistency for now
    runs-on: ubuntu-latest # Use the latest available Ubuntu runner
    outputs:
      # Define the output 'matrix' which will contain the JSON object for the strategy
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      # Step 1.1: Checkout the repository containing this workflow
      - name: Checkout Repository Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1 # Fetch only the latest commit for efficiency

      # Step 1.2: Install necessary command-line tools
      - name: Install yq and jq
        run: sudo apt-get update -y && sudo apt-get install -y yq jq

      # Step 1.3: Build the organization matrix
      # This script determines the list of organizations to process.
      - name: Build org matrix
        id: set-matrix # Give this step an ID so its output can be referenced
        shell: bash    # Use bash shell for the script
        env:
          # Pass workflow inputs to the script environment
          MODE: ${{ github.event.inputs.mode || 'review' }} # Default to 'review' if not manually triggered
          PROJECT_ORG: ${{ github.event.inputs.project_org }}
          # PROJECT_REPO is now handled within the classify job if provided for induction
        run: |
          set -euo pipefail # Keep strict mode here as it's simpler logic

          declare -a org_list

          # --- Determine Org List ---
          if [[ "$MODE" == "induction" ]]; then
            if [[ -z "$PROJECT_ORG" ]]; then echo "ERROR: Project org must be provided for induction mode." >&2; exit 1; fi
            org_list+=("$PROJECT_ORG")
            echo "Processing single org (Induction): $PROJECT_ORG" >&2
          else
            # Use the env var for the projects config path
            if [[ ! -f "${{ env.PROJECT_CONFIG_PATH }}" ]]; then echo "ERROR: ${{ env.PROJECT_CONFIG_PATH }} not found!" >&2; exit 1; fi
            # Read orgs into the bash array using yq and mapfile
            mapfile -t org_list < <(yq -r '.orgs[] // ""' "${{ env.PROJECT_CONFIG_PATH }}" | grep -v '^$' ) # Read orgs, filter empty lines
            echo "Read ${#org_list[@]} orgs from ${{ env.PROJECT_CONFIG_PATH }}" >&2
          fi

          # --- Create Matrix ---
          total_orgs=${#org_list[@]}
          echo "Total organizations to process: $total_orgs" >&2
          if [ $total_orgs -eq 0 ]; then
            echo "ERROR: No organizations found to process." >&2
            echo "matrix={\"include\":[]}" >> "$GITHUB_OUTPUT"
            exit 0 # Exit successfully but with empty matrix
          fi

          # Prepare the 'include' array for the matrix: [ {"org": "org1"}, {"org": "org2"}, ... ]
          matrix_include_json=$(printf '%s\n' "${org_list[@]}" | jq -R '{org: .}' | jq -sc .)

          # Final matrix object structure: { "include": [ { "org": "org1" }, ... ] }
          final_matrix_json="{\"include\":${matrix_include_json}}"

          echo "matrix=${final_matrix_json}" >> "$GITHUB_OUTPUT"
          echo "Generated matrix for $total_orgs organizations." >&2
          echo "Matrix structure: $(echo $final_matrix_json | jq -c . | cut -c 1-200)..." >&2


  # =============================================================================
  # JOB 2: Classify Repositories per Organization
  # PURPOSE: Runs the classification logic for all repositories within a specific organization.
  #          This job uses a matrix strategy based on the organizations identified previously.
  # INPUT:   The 'matrix' output from 'enumerate-projects', containing organization names.
  # PROCESS: - For each organization job instance:
  #          - Checks out the main governance-automation repo.
  #          - Sets up Node.js and installs dependencies for the local action.
  #          - Lists all repositories within the current organization.
  #          - Loops through each repository slug.
  #          - For each repo: Clones it, runs the classification Node.js script directly,
  #            saves the result to a uniquely named file in a results directory.
  #          - After the loop, uses actions/upload-artifact to upload all results.
  # =============================================================================
  classify:
    needs: enumerate-projects # Depends on the 'enumerate-projects' job
    # Condition to prevent running if the matrix 'include' array is empty
    if: ${{ needs.enumerate-projects.outputs.matrix != '' && fromJson(needs.enumerate-projects.outputs.matrix).include[0] != null }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false # Allow other orgs to process if one fails
      matrix: ${{ fromJson(needs.enumerate-projects.outputs.matrix) }} # Matrix iterates over org objects: { "org": "..." }
    steps:

      # Step 2.1: Checkout the main branch of this (governance-automation) repository.
      - name: Checkout governance-automation code (Org ${{ matrix.org }})
        uses: actions/checkout@v4
        with:
          ref: main

      # Step 2.2: Setup Node.js environment (once per org job).
      - name: Setup Node.js (Org ${{ matrix.org }})
        uses: actions/setup-node@v4
        with:
          node-version: '16'

      # Step 2.3: Install dependencies for the local classification action (once per org job).
      - name: Install Action Dependencies (Org ${{ matrix.org }})
        run: npm install
        # Use the env var for the action path
        working-directory: ${{ env.CLASSIFY_ACTION_PATH }}

      # Step 2.4: Process all repositories within the current organization.
      # This script now includes explicit error checking and saves results locally.
      - name: Process Repositories for Org ${{ matrix.org }}
        id: process-repos # Give step an ID
        shell: bash
        env:
          # Pass specific repo slug if provided in induction mode, otherwise process all
          INDUCTION_REPO_SLUG: ${{ github.event.inputs.project_repo }}
          MODE: ${{ github.event.inputs.mode || 'review' }}
          # Pass the config path env var to the script environment
          CLASSIFY_CONFIG_FILE_PATH: ${{ env.CLASSIFY_CONFIG_PATH }}
          CLASSIFY_ACTION_DIR: ${{ env.CLASSIFY_ACTION_PATH }}
          # Explicitly set GH_TOKEN for gh CLI (uses LFN_ADMIN_TOKEN)
          GH_TOKEN: ${{ env.GITHUB_TOKEN }}
        run: |
          # Re-enable strict error checking
          set -euo pipefail
          # set -x # Uncomment for extreme debugging

          current_org="${{ matrix.org }}"
          config_path="$CLASSIFY_CONFIG_FILE_PATH"
          action_dir="$CLASSIFY_ACTION_DIR"
          results_dir="./classification-results" # Directory to store results
          repo_processed_count=0
          repo_error_count=0

          # Create results directory
          mkdir -p "$results_dir" # Error handled by set -e

          # Check if gh is installed (needed for repo list)
          if ! command -v gh &> /dev/null; then echo "ERROR: gh cli not found." >&2; exit 1; fi
          # Verify authentication using the provided token (GH_TOKEN takes precedence)
          echo "Verifying gh CLI authentication (using LFN_ADMIN_TOKEN)..." >&2
          gh auth status # Error handled by set -e
          echo "gh CLI authenticated with LFN_ADMIN_TOKEN." >&2

          # --- List Repositories for the Current Org ---
          declare -a org_repos
          echo "Listing repositories for organization: $current_org..." >&2

          if [[ "$MODE" == "induction" ]] && [[ -n "$INDUCTION_REPO_SLUG" ]] && [[ "$INDUCTION_REPO_SLUG" == "$current_org/"* ]]; then
             echo "Induction mode with specific repo: $INDUCTION_REPO_SLUG" >&2
             org_repos+=("$INDUCTION_REPO_SLUG")
          else
             echo "Attempting: gh repo list \"$current_org\" --limit 1000 --json name --visibility=public -q '.'" >&2
             repo_list_output=$(gh repo list "$current_org" --limit 1000 --json name --visibility=public -q '.' 2>&1)
             gh_exit_code=$?
             echo "gh repo list exit code: $gh_exit_code" >&2

             if [[ $gh_exit_code -ne 0 ]]; then
                 echo "::error::Failed to list repos for '$current_org'. gh exit code: $gh_exit_code."
                 echo "gh repo list output on error: $repo_list_output" >&2
                 # Exit non-zero to fail the job if listing fails
                 exit 1
             fi
             repo_list_json="$repo_list_output"
             if echo "$repo_list_json" | jq -e '. == null or length == 0' > /dev/null; then
                 echo "::warning::No public repositories found for '$current_org' or org is inaccessible. Skipping org."
                 # Exit zero because no repos is not a failure of the script itself
                 exit 0
             fi
             # Use temporary file for mapfile input to handle potential large outputs safely
             jq -r '.[].name' <<< "$repo_list_json" > repo_names.tmp
             mapfile -t repo_names_array < repo_names.tmp
             rm repo_names.tmp
             for name in "${repo_names_array[@]}"; do
                org_repos+=("$current_org/$name")
             done
          fi

          echo "Found ${#org_repos[@]} repositories to process for $current_org." >&2
          if [ ${#org_repos[@]} -eq 0 ]; then
             echo "No repositories to process for $current_org." >&2
             exit 0
          fi

          # --- Loop Through Repositories in this Org ---
          for repo_slug in "${org_repos[@]}"; do
            if [[ -z "$repo_slug" ]]; then continue; fi

            echo
            echo "--- Processing repository: $repo_slug ---" >&2
            target_repo_path="./repo_temp"
            safe_name=$(echo "$repo_slug" | sed 's|/|--|g')
            # Save result directly to the results directory with the final name
            result_json_path="${results_dir}/${safe_name}.json"
            repo_failed=false

            # Clean up from previous iteration (only target repo dir)
            # Allow rm to fail without exiting script using || true
            rm -rf "$target_repo_path" || echo "::warning::Failed to remove $target_repo_path (continuing)"

            # --- Checkout target repo ---
            echo "Cloning $repo_slug..." >&2
            # Use a subshell and || true to capture output even on failure with set -e
            git_output=$( (git clone --depth 1 "https://github-actions:${GH_TOKEN}@github.com/${repo_slug}.git" "$target_repo_path") 2>&1 || true )
            git_exit_code=$? # Check the exit code after the command

            phase_value="Unknown"
            checkout_successful=false
            if [[ $git_exit_code -eq 0 ]]; then
              echo "Clone successful." >&2
              checkout_successful=true
            else
              echo "::error::Failed to clone $repo_slug. Exit code: $git_exit_code."
              echo "Git Output: $git_output"
              phase_value="Checkout Failed"
              repo_failed=true
              printf '{"phase": "%s", "error": "Checkout failed", "details": "%s"}\n' "$phase_value" "$(echo "$git_output" | jq -Rsa .)" > "$result_json_path"
            fi

            # --- Run Classification Script ---
            if [[ "$checkout_successful" == true ]]; then
              echo "Running classification script for $repo_slug..." >&2
              # Run node script
              INPUT_REPO="$repo_slug" \
              INPUT_CONFIG_PATH="$config_path" \
              GITHUB_TOKEN="${GH_TOKEN}" \
              node "${action_dir}/index.js" # This script should write repo.json
              node_exit_code=$?

              if [[ $node_exit_code -ne 0 ]]; then
                 echo "::error::Classification script failed for $repo_slug with exit code $node_exit_code."
                 phase_value="Classification Error"
                 repo_failed=true
                 printf '{"phase": "%s", "error": "Classification script failed", "exit_code": %s}\n' "$phase_value" "$node_exit_code" > "$result_json_path"
              elif [[ -f "repo.json" ]]; then
                 # Move the generated repo.json to the final destination
                 mv "repo.json" "$result_json_path" # Error handled by set -e
                 echo "Classification script ran, result saved to $result_json_path" >&2
                 phase_value=$(jq -r '.phase // "Unknown"' "$result_json_path" 2>/dev/null || echo "Read Error")
                 if [[ "$phase_value" == "Read Error" ]]; then
                    echo "::error::Failed to read phase from generated $result_json_path for $repo_slug"
                    repo_failed=true
                    printf '{"phase": "%s", "error": "Failed to read phase from script output"}\n' "$phase_value" > "$result_json_path"
                 fi
              else
                 echo "::error::Classification script completed successfully but did not produce repo.json for $repo_slug"
                 phase_value="Classification Error"
                 repo_failed=true
                 printf '{"phase": "%s", "error": "Classification script did not produce output file"}\n' "$phase_value" > "$result_json_path"
              fi
            fi # end if checkout_successful

            echo "Final phase for $repo_slug: $phase_value" >&2

            # --- Artifact Upload moved to separate step ---

            # Increment counters (No error check needed)
            ((repo_processed_count++))
            if [[ "$repo_failed" == true ]]; then
               ((repo_error_count++))
               # Ensure an error file exists if repo failed before file creation
               if [[ ! -f "$result_json_path" ]]; then
                  printf '{"phase": "Error", "error": "Processing failed before result generation"}\n' > "$result_json_path"
               fi
            fi

            # Clean up repo clone for next iteration
            # Allow rm to fail without exiting script using || true
            rm -rf "$target_repo_path" || echo "::warning::Failed to remove $target_repo_path (continuing)"
            echo "--- Finished processing repository: $repo_slug ---" >&2

          done # End of loop through repos for the org

          echo "Finished processing Org ${current_org}. Processed: $repo_processed_count, Errors: $repo_error_count." >&2

          # Decide if the job should fail if any repo had an error
          if [[ $repo_error_count -gt 0 ]]; then
            echo "::error::Encountered $repo_error_count errors while processing repositories for $current_org."
            # exit 1 # Uncomment this line to make the whole org job fail if any repo fails
          fi

      # Step 2.5: Upload all generated result files as a single artifact for this org job
      - name: Upload Classification Artifacts for Org ${{ matrix.org }}
        uses: actions/upload-artifact@v4
        if: always() # Upload even if some repos failed
        with:
          name: classification-results-${{ matrix.org }} # Artifact name includes the org
          path: classification-results/ # Upload the contents of the results directory
          retention-days: 5 # Optional: Adjust retention


  # =============================================================================
  # JOB 3: Publish Report
  # PURPOSE: Aggregates the classification results from all repositories (across
  #          all orgs), generates a Markdown summary report, and posts/updates
  #          that report as a GitHub issue in the main governance-automation repository.
  # INPUT:   Artifacts uploaded by the 'classify' job instances (one per org).
  # PROCESS: - Downloads all artifacts.
  #          - Parses each downloaded JSON file to get the repo and phase.
  #          - Builds the Markdown report ('summary.md') as before.
  #          - Uses github-script to find/create/update the summary issue.
  #          - Optionally notifies Slack.
  # =============================================================================
  publish-report:
    needs: classify # Depends on the completion of all 'classify' org jobs
    runs-on: ubuntu-latest
    if: always() # Run even if some classify jobs failed
    steps:
      # Step 3.1: Download all artifacts produced by the 'classify' jobs.
      # Each artifact contains results for one org.
      - name: Download classification artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts # Download all artifacts into subdirectories here

      # Step 3.1.1: DEBUG - List downloaded files
      - name: List downloaded files
        if: always()
        run: |
          echo "Listing contents of ./artifacts directory:"
          ls -R artifacts || echo "Artifacts directory not found or empty."
          echo "-----------------------------------------"

      # Step 3.2: Build the Markdown Summary Report.
      - name: Build Markdown Report
        id: build-md
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v jq &> /dev/null; then
            echo "jq not found, installing..." >&2
            sudo apt-get update -y && sudo apt-get install -y jq
          fi

          declare -A rows_data
          echo "Scanning artifacts directory: $(pwd)/artifacts" >&2

          # Check if artifacts directory exists and has content
          if [ ! -d "artifacts" ] || [ -z "$(ls -A artifacts)" ]; then
              echo "WARNING: Artifacts directory is missing or empty. No artifacts to process."
              # Create an empty report if no artifacts were downloaded
              echo "# LFN Project Lifecycle Summary" > summary.md
              echo "" >> summary.md
              echo "*No artifacts found. Check 'classify' job logs for errors (e.g., artifact upload failures).*" >> summary.md
          else
              # Find all downloaded JSON files (*.json) inside the artifact subdirectories
              # Structure is artifacts/classification-results-<org-name>/org--repo.json
              while IFS= read -r -d $'\0' file; do
                # Check if the found item is actually a file before processing
                if [[ ! -f "$file" ]]; then
                    echo "Warning: Skipping non-file item found by find: $file" >&2
                    continue
                fi

                # Extract org--repo from filename
                artifact_name_with_ext=$(basename "$file") # org--repo.json
                artifact_name=${artifact_name_with_ext%.json} # org--repo

                full=${artifact_name//--/\/}
                project=${full%%/*}
                repo=${full#*/}

                # Attempt to read phase, handle potential errors during read/parse
                phase=$(jq -r '.phase // "Unknown"' "$file" 2>/dev/null)
                jq_exit_code=$?
                # Check jq exit code and if phase is null/empty string
                if [[ $jq_exit_code -ne 0 ]] || [[ -z "$phase" ]] || [[ "$phase" == "null" ]]; then
                  # If jq failed or phase is empty/null, try reading error field
                  error_msg=$(jq -r '.error // ""' "$file" 2>/dev/null)
                  if [[ -n "$error_msg" ]]; then
                     # Sanitize error message for Markdown table (optional)
                     # error_msg=$(echo "$error_msg" | sed 's/|/\\|/g')
                     phase="Error: $error_msg" # Use error message as phase
                  else
                     phase="Unknown (Parse Error)" # Fallback if no error field
                  fi
                  echo "Warning: Could not parse phase or phase was null/empty in $file ($artifact_name). Setting phase to '$phase'." >&2
                fi

                row_line="| [$repo](https://github.com/$project/$repo) | $phase |"
                if [[ -z "${rows_data[$project]:-}" ]]; then
                  rows_data[$project]="$row_line"
                else
                  rows_data[$project]+=$'\n'"$row_line"
                fi
              # Find *.json files within any subdirectory of artifacts/
              # Corrected find command for the structure created by upload-artifact
              done < <(find artifacts -mindepth 2 -name '*.json' -print0)


              if [ ${#rows_data[@]} -eq 0 ]; then
                echo "WARNING: No valid artifact data found to generate report, although artifacts directory exists and files were found." >&2
                echo "# LFN Project Lifecycle Summary" > summary.md
                echo "" >> summary.md
                echo "*No project data processed successfully. Check the 'classify' job logs and artifact contents for errors.*" >> summary.md
              else
                {
                  echo "# LFN Project Lifecycle Summary"
                  echo ""
                  echo "Generated on: $(date -u)"
                  echo "Workflow Run: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}>"
                  echo ""
                  sorted_projects=()
                  while IFS= read -r key; do
                      sorted_projects+=("$key")
                  done < <(printf '%s\n' "${!rows_data[@]}" | sort)

                  for project in "${sorted_projects[@]}"; do
                    echo
                    echo "## $project"
                    echo "| Repository | Phase |"
                    echo "|------------|-------|"
                    # Sort rows: Errors/Unknown first, then by phase, then by repo name
                    mapfile -t sorted_lines < <(printf '%s\n' "${rows_data[$project]}" | awk -F'|' '{gsub(/^[ \t]+|[ \t]+$/, "", $3); if ($3 ~ /^Error|^Unknown|^Checkout Failed|^Classification Error/) print "0"$0; else print "1"$0 }' | sort -t'|' -k1,1 -k3,3 -k2,2 | sed 's/^.//')
                    printf '%s\n' "${sorted_lines[@]}"
                  done
                } > summary.md
              fi
          fi # End check for artifacts directory

          echo "Generated summary.md:" >&2
          cat summary.md >&2

          {
            echo 'summary<<EOF'
            cat summary.md
            echo 'EOF'
          } >> "$GITHUB_OUTPUT"

          cat summary.md >> "$GITHUB_STEP_SUMMARY"

      # Step 3.3: Create or Update the Governance Summary Issue
      - name: Create or update governance issue
        uses: actions/github-script@v7
        with:
          github-token: ${{ env.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            // Note: 'core', 'github', and 'context' are automatically provided by actions/github-script@v7
            let body = "Failed to read summary.md";
            if (fs.existsSync('summary.md')) {
              body = fs.readFileSync('summary.md', 'utf8');
            } else {
              core.warning("summary.md not found for issue creation/update.");
              body = "Error: Workflow failed to generate summary report.";
            }
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const title = 'Automated LFN Project Lifecycle Summary';
            const token = process.env.GITHUB_TOKEN;
            if (!token) {
              core.setFailed('GITHUB_TOKEN not found in environment.');
              return;
            }
            // Use the pre-authenticated 'github' object provided by the action
            try {
              const issues = await github.paginate(github.rest.issues.listForRepo, {
                owner, repo, labels: 'lfn-governance', state: 'open'
              });
              const existing = issues.find(i => i.title === title);
              if (existing) {
                core.info(`Found existing issue #${existing.number}. Updating...`);
                await github.rest.issues.update({ owner, repo, issue_number: existing.number, body });
                core.info(`Updated issue #${existing.number}`);
              } else {
                core.info("No existing governance issue found. Creating new issue...");
                await github.rest.issues.create({ owner, repo, title, body, labels: ['lfn-governance'] });
                core.info('Created new governance issue');
              }
            } catch (error) {
              core.setFailed(`Failed to create or update governance issue: ${error.message}`);
              console.error("Error details:", error);
            }

      # Step 3.4: Optional Slack Notification
      - name: Notify Slack (optional)
        if: ${{ env.SLACK_WEBHOOK_URL != '' }}
        uses: slackapi/slack-github-action@v1.24.0
        with:
          payload: |
            {
              "text": ":clipboard: LFN governance summary updated for *${{ github.repository }}* – <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|view run>"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
